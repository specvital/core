---
allowed-tools: Bash(*), Read, Write, Grep, Glob
description: Validate DomainHints extraction quality by detecting noise patterns and statistical anomalies
---

# Domain Hints Quality Validation Command

## Purpose

Validate that DomainHints extraction produces clean, domain-relevant data by detecting:

- **Noise Patterns**: Empty strings, parser artifacts (`[.`), meaningless tokens (`fn`, `Ok`)
- **Statistical Anomalies**: Unusual NULL ratios, abnormal average counts
- **Regressions**: Unexpected changes in extraction results

This is a **data quality assurance tool** for the DomainHints extraction engine.

## User Input

```text
$ARGUMENTS
```

**Interpretation**:

| Input                  | Action                                       |
| ---------------------- | -------------------------------------------- |
| (empty)                | Run full validation on all integration repos |
| `{repo-name}`          | Validate specific repo from repos.yaml       |
| `{github-url}`         | Clone and validate external repo             |
| `noise` / `patterns`   | Focus on noise pattern detection only        |
| `stats` / `statistics` | Focus on statistical analysis only           |
| `compare {framework}`  | Compare framework stats vs baseline          |

---

## Known Noise Patterns

These patterns indicate extraction bugs or low-quality data:

### Critical (Must Filter)

| Pattern | Type            | Description                   | Severity |
| ------- | --------------- | ----------------------------- | -------- |
| `""`    | Empty           | Empty string in Calls/Imports | üî¥ Error |
| `[.`    | Parser artifact | Spread array handling bug     | üî¥ Error |
| `.`     | Single char     | Dot only                      | üî¥ Error |

### Warning (Should Filter)

| Pattern         | Type        | Description          | Severity   |
| --------------- | ----------- | -------------------- | ---------- |
| `fn`            | Meaningless | Standalone fn() call | üü° Warning |
| `Ok`            | Rust stdlib | Enum constructor     | üü° Warning |
| `Err`           | Rust stdlib | Enum constructor     | üü° Warning |
| `Some`          | Rust stdlib | Enum constructor     | üü° Warning |
| `None`          | Rust stdlib | Enum constructor     | üü° Warning |
| 1-2 char tokens | Too short   | Likely noise         | üü° Warning |

### Regex Patterns

```go
// Parser artifacts
"^[\\[\\]\\(\\)\\{\\}]+$"  // Bracket-only tokens

// Language keywords mistakenly captured
"^(fn|if|for|let|var|const)$"
```

---

## Statistical Baselines

Expected values by framework (from production data):

| Framework  | NULL Ratio | Avg Imports | Avg Calls | Notes                     |
| ---------- | ---------- | ----------- | --------- | ------------------------- |
| cypress    | ~21%       | 2-5         | 5-15      | E2E tests have no imports |
| jest       | ~5%        | 3-10        | 10-20     |                           |
| vitest     | ~7%        | 3-10        | 10-20     |                           |
| go-testing | ~2%        | 3-8         | 8-15      |                           |
| playwright | ~3%        | 2-6         | 10-25     |                           |
| cargo-test | ~5%        | 2-6         | 5-15      |                           |

**Anomaly Thresholds**:

- NULL ratio increase > 5%: üî¥ Error
- Avg imports/calls drop > 20%: üü° Warning

---

## Workflow

### Phase 1: Setup

**1.1 Determine validation scope**:

```bash
# Check what repos are available
cat tests/integration/repos.yaml | grep "name:"
```

**1.2 Select target(s)**:

- Empty input ‚Üí all repos in repos.yaml
- Specific repo ‚Üí filter to that repo
- External URL ‚Üí clone to /tmp

### Phase 2: Run Parser with DomainHints

```bash
cd /workspaces/specvital-core

# For integration test repos (already cached)
just scan /path/to/cached/repo --json 2>/dev/null | jq '.'

# Or run integration test to get data
go test -tags integration ./tests/integration/... -v -run "TestScan/{repo-name}" 2>&1
```

### Phase 3: Extract DomainHints Data

**3.1 Collect all DomainHints from scan result**:

Parse the JSON output to extract:

- All `Imports` arrays
- All `Calls` arrays
- Count of NULL vs non-NULL DomainHints

**3.2 Calculate statistics**:

```
Total files: N
Files with hints: M
NULL ratio: (N-M)/N * 100%
Avg imports per file: sum(imports) / M
Avg calls per file: sum(calls) / M
```

### Phase 4: Noise Pattern Detection

**4.1 Check all Imports for noise patterns**:

```bash
# Pseudo-code
for import in all_imports:
    if import == "":
        report_error("Empty import found")
    if len(import) <= 2:
        report_warning(f"Short import: {import}")
```

**4.2 Check all Calls for noise patterns**:

```bash
# Pseudo-code
for call in all_calls:
    if call == "":
        report_error("Empty call found")
    if call in ["[.", ".", "fn", "Ok", "Err", "Some", "None"]:
        report_warning(f"Noise pattern: {call}")
    if matches_regex(call, "^[\\[\\]\\(\\)\\{\\}]+$"):
        report_error(f"Parser artifact: {call}")
```

### Phase 5: Statistical Analysis

**5.1 Compare against baselines**:

```
Framework: {framework}
Expected NULL ratio: {baseline}%
Actual NULL ratio: {actual}%
Delta: {delta}%
Status: {PASS|WARN|FAIL}
```

**5.2 Detect anomalies**:

- NULL ratio significantly higher than baseline
- Average imports/calls significantly lower
- Unusual distribution patterns

### Phase 6: Generate Report

**Report Location**: `/workspaces/specvital-core/domain-hints-quality-report.md`

**Language**: üá∞üá∑ Korean (ÌïúÍµ≠Ïñ¥) - MANDATORY

---

## Report Template

```markdown
# DomainHints ÌíàÏßà Í≤ÄÏ¶ù Î≥¥Í≥†ÏÑú

**ÏùºÏãú**: {timestamp}
**ÎåÄÏÉÅ**: {repo-name or "Ï†ÑÏ≤¥ ÌÜµÌï© ÌÖåÏä§Ìä∏ Ï†ÄÏû•ÏÜå"}
**ÌîÑÎ†àÏûÑÏõåÌÅ¨**: {framework(s)}

---

## üìä ÏöîÏïΩ

| Ìï≠Î™©             | Í≤∞Í≥º                          |
| ---------------- | ----------------------------- |
| Í≤ÄÏÇ¨ ÌååÏùº Ïàò     | {n}                           |
| DomainHints Ï°¥Ïû¨ | {n} ({percentage}%)           |
| ÎÖ∏Ïù¥Ï¶à Ìå®ÌÑ¥ Î∞úÍ≤¨ | {n}Í±¥                         |
| ÌÜµÍ≥Ñ Ïù¥ÏÉÅÏπò      | {n}Í±¥                         |
| **ÏµúÏ¢Ö ÏÉÅÌÉú**    | {‚úÖ PASS / ‚ö†Ô∏è WARN / ‚ùå FAIL} |

---

## üîç ÎÖ∏Ïù¥Ï¶à Ìå®ÌÑ¥ Í≤ÄÏÇ¨

### Î∞úÍ≤¨Îêú ÎÖ∏Ïù¥Ï¶à

| Ìå®ÌÑ¥        | ÌÉÄÏûÖ   | Î∞úÍ≤¨ ÌöüÏàò | ÏÉòÌîå ÌååÏùº     |
| ----------- | ------ | --------- | ------------- |
| `{pattern}` | {type} | {count}   | `{file_path}` |

### Ìå®ÌÑ¥Î≥Ñ ÏÉÅÏÑ∏

#### `{pattern}` ({count}Í±¥)

**Ï∂úÏ≤ò Î∂ÑÏÑù**:

- {repo/framework}: {count}Í±¥

**ÏõêÏù∏ Ï∂îÏ†ï**:
{description of likely cause}

---

## üìà ÌÜµÍ≥Ñ Î∂ÑÏÑù

### ÌîÑÎ†àÏûÑÏõåÌÅ¨Î≥Ñ ÌòÑÌô©

| ÌîÑÎ†àÏûÑÏõåÌÅ¨  | ÌååÏùº Ïàò | NULL ÎπÑÏú® | Í∏∞Ï§ÄÏÑ†      | ÏÉÅÌÉú     |
| ----------- | ------- | --------- | ----------- | -------- |
| {framework} | {n}     | {actual}% | {baseline}% | {status} |

### Imports Î∂ÑÌè¨

| ÏßÄÌëú            | Í∞í  |
| --------------- | --- |
| Ï¥ù Í≥†Ïú† imports | {n} |
| ÌååÏùºÎãπ ÌèâÍ∑†     | {n} |
| ÏµúÎåÄ            | {n} |

**Top 10 Imports**:

| Import     | Ï∂úÌòÑ ÌöüÏàò |
| ---------- | --------- |
| `{import}` | {count}   |

### Calls Î∂ÑÌè¨

| ÏßÄÌëú          | Í∞í  |
| ------------- | --- |
| Ï¥ù Í≥†Ïú† calls | {n} |
| ÌååÏùºÎãπ ÌèâÍ∑†   | {n} |
| ÏµúÎåÄ          | {n} |

**Top 10 Calls**:

| Call     | Ï∂úÌòÑ ÌöüÏàò |
| -------- | --------- |
| `{call}` | {count}   |

---

## üêõ Î∞úÍ≤¨Îêú Î¨∏Ï†ú

### üî¥ Critical (Ï¶âÏãú ÏàòÏ†ï ÌïÑÏöî)

{IF critical issues exist}

1. **{issue}**: {description}
   - ÏòÅÌñ• Î≤îÏúÑ: {scope}
   - Í∂åÏû• Ï°∞Ïπò: {action}
     {ELSE}
     ÏóÜÏùå
     {ENDIF}

### üü° Warning (Í≤ÄÌÜ† ÌïÑÏöî)

{IF warnings exist}

1. **{issue}**: {description}
   - ÏòÅÌñ• Î≤îÏúÑ: {scope}
   - Í∂åÏû• Ï°∞Ïπò: {action}
     {ELSE}
     ÏóÜÏùå
     {ENDIF}

---

## üìã Í≤∞Î°†

{Based on findings}

**If PASS**:

> DomainHints Ï∂îÏ∂ú ÌíàÏßàÏù¥ ÏñëÌò∏Ìï©ÎãàÎã§.
>
> - ÎÖ∏Ïù¥Ï¶à Ìå®ÌÑ¥: ÏóÜÏùå
> - ÌÜµÍ≥Ñ Ïù¥ÏÉÅÏπò: ÏóÜÏùå

**If WARN**:

> Í≤ΩÎØ∏Ìïú ÌíàÏßà Ïù¥ÏäàÍ∞Ä Î∞úÍ≤¨ÎêòÏóàÏäµÎãàÎã§.
>
> - {list of warnings}
>   Í∂åÏû•: Îã§Ïùå Î¶¥Î¶¨Ïä§ÏóêÏÑú Í∞úÏÑ† Í≤ÄÌÜ†

**If FAIL**:

> Ïã¨Í∞ÅÌïú ÌíàÏßà Ïù¥ÏäàÍ∞Ä Î∞úÍ≤¨ÎêòÏóàÏäµÎãàÎã§.
>
> - {list of critical issues}
>   **Ï¶âÏãú ÏàòÏ†ï ÌïÑÏöî**

---

## üìù Í∂åÏû• Ï°∞Ïπò

- [ ] {action item 1}
- [ ] {action item 2}
```

---

## Validation Criteria

### ‚úÖ PASS

- No critical noise patterns found
- NULL ratio within baseline ¬± 5%
- No statistical anomalies

### ‚ö†Ô∏è WARN

- Warning-level noise patterns found (fn, Ok, etc.)
- NULL ratio slightly above baseline (5-10%)
- Minor statistical deviations

### ‚ùå FAIL

- Critical noise patterns found (empty string, [., etc.)
- NULL ratio significantly above baseline (>10%)
- Parser artifacts detected

---

## Key Rules

### ‚úÖ Must Do

- **Write report in Korean (ÌïúÍµ≠Ïñ¥Î°ú Î¶¨Ìè¨Ìä∏ ÏûëÏÑ±)** ‚Üê CRITICAL
- Check ALL Imports and Calls for noise patterns
- Compare statistics against framework baselines
- Provide actionable recommendations
- Include sample file paths for each issue

### ‚ùå Must Not Do

- **Write report in English** ‚Üê Use Korean only
- Ignore any noise pattern (even 1 = potential bug)
- Skip statistical analysis
- Miss framework-specific baselines (e.g., Cypress 21% NULL is normal)

### üéØ Principles

1. **Quality First**: Even minor noise degrades AI domain classification
2. **Quantitative**: Measure exact counts and percentages
3. **Comparative**: Always compare against baselines
4. **Actionable**: Every issue needs a clear fix recommendation

---

## Quick Commands

```bash
# Full validation on all repos
/validate-domain-hints

# Single repo
/validate-domain-hints grafana

# External repo
/validate-domain-hints https://github.com/vercel/next.js

# Focus on noise only
/validate-domain-hints noise

# Compare Cypress stats
/validate-domain-hints compare cypress
```

---

## Execution

Now execute the DomainHints quality validation according to the guidelines above.
